---
title: "genome_blast"
output: html_document
date: "2024-06-30"
---

### Split the files
```{bash}
#!/bin/bash

# Input and output directories
input_file="/home/shared/8TB_HDD_02/graceleuchtenberger/Github/byssus-exp-analysis/data/ncbi_dataset/data/GCF_036588685.1/cds_from_genomic.fasta"
output_dir="/home/shared/8TB_HDD_02/graceleuchtenberger/Github/byssus-exp-analysis/data/splits"

# Make sure the output directory exists
mkdir -p $output_dir

# Split the input file
awk -v max_seqs=5 -v out_dir="$output_dir/split_" '
  BEGIN {seq_count=0; file_count=1}
  /^>/ {if(seq_count % max_seqs == 0) {close(out_file); out_file=sprintf("%s%d.fasta", out_dir, file_count++);} seq_count++}
  {print >> out_file}
' $input_file

```

### Uniprot request
```{bash}
# Step 2: Submit Jobs and Collect Job IDs
for split_file in "$split_dir"/*.fasta; do
  response=$(curl -s -X POST "https://www.uniprot.org/blast/" \
       -F "file=@${split_file}" \
       -F "program=blastp" \
       -F "database=uniprotkb_trembl" \
       -F "email=${email}")

  job_id=$(echo $response | grep -oP '(?<=RID = )\w+')
  echo "Submitted $split_file, job ID: $job_id"

  # Save job ID to a file for later retrieval
  echo $job_id >> job_ids.txt
  sleep 1 # Add a delay to avoid overwhelming the server
done

# Step 3: Check Job Status and Download Results
while read -r job_id; do
  echo "Checking status for job ID: $job_id"

  # Poll the job status until it is completed
  while true; do
    status=$(curl -s "https://www.uniprot.org/blast/results/${job_id}.json" | jq -r '.status')
    echo "Status: $status"

    if [ "$status" == "DONE" ]; then
      # Download the results
      curl -o "${output_results_dir}/${job_id}.xml" "https://www.uniprot.org/blast/results/${job_id}.xml"
      echo "Results for job ID: $job_id downloaded."
      break
    elif [ "$status" == "FAILURE" ]; then
      echo "Job $job_id failed."
      break
    else
      # Wait for a while before checking again
      sleep 60
    fi
  done
done < job_ids.txt



```






